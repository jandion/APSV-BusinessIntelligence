{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell downloads the required data set to carry out the workshop. This kind of code works on Google Colab, and if you are using another platform to run the notebook, you might need to manually download the data directory from the GitHub repository and put it in the same path as the notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/APSV-UPM/BusinessIntelligence/main/data/data.csv > data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will work with a data set representing a logistics process. These data contain events from a logistics process in which a series of goods or items are transported from one station to another by train. It is based on a real-world process, but it has been simplified to make it easier to work with.\n",
    "Each step in the process is represented by an event, and the events have a timestamp that represents when the event was recorded. The types of events appear in Spanish; the following table is a translation of these into English.\n",
    "\n",
    "Spanish | English\n",
    "---|---\n",
    "'Comienzo de ruta'         | 'START OF ROUTE'\n",
    "'Descarga de vagones'      | 'END OF WAGON UNLOADING'\n",
    "'Final carga'              | 'END OF WAGON LOADING'\n",
    "'Final de ruta'            | 'END OF ROUTE'\n",
    "'Llegada de vagones'       | 'ARRIVAL OF WAGONS TO DESTINATION'\n",
    "'Salida de vagones'        | 'DEPARTURE OF WAGONS FROM ORIGIN'\n",
    "\n",
    "Our goal is to obtain as much information as we can from this data set. We will achieve this in two ways: we will answer questions with numeric values (e.g., how many trains take part in the process?) or we will generate some charts to present information in a visual way (e.g. how is the distribution of items transported throughout the year?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset exploration\n",
    "Any project related to data analysis starts with a study of the data itself. \n",
    "* What kind of data do we have?\n",
    "* How is it organized? How many columns does each dataframe have?\n",
    "* Are there wrong or missing values?\n",
    "* What does each value of a column mean? How many different values are there in each column?\n",
    "\n",
    "With the examples we saw in the previous workshop we try to answer those questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.event.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use as many cells as you need for your exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "After a first view of the data and before starting to work with it, we must clean it. This process is called preprocessing, and it is crucial to be able to obtain good results. We will discard invalid data, fill missing values, drop redundant information, correct typos, etc. We need to create a data set with the following restrictions.\n",
    "\n",
    "* All columns must contain relevant information. If a column does not contain relevant information, it should be removed using the method `data.drop(columns = [column_name])` (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
    "* Duplicate rows should be removed using the method `data.drop_duplicates()` (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    "* Rows with future dates (after September 30, 2025) should be eliminated\n",
    "* All fields should have a valid value. \n",
    "* String columns cannot be empty or null\n",
    "* Numeric columns should be in the correct ranges. The maximum cargo is 200 and the maximum fuel 2000.\n",
    "* Rows with null or incorrect values should be discarded (https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html). This includes rows with illegal values according to the dataset description (e.g. a negative number of items). \n",
    "* The types of the columns must correspond to the type of data they contain (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html)\n",
    "\n",
    "Python and Pandas have a multitude of methods that make it easier to work with dates. In this workshop, it can be useful to use methods that allow us to obtain certain fragments of a date (hour of day, the day of the week, etc.) https://docs.python.org/3/library/datetime.html. An effective way to apply a change to an entire column is with a syntax like `df.date.dt.hour`, which allows us to get the hour of the dates in the column `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics\n",
    "\n",
    "Once we know about the data that we are using and have cleaned it, we need to ask what kind of useful information we can extract from those data. It is a good idea to make a kind of brainstorming of possible questions, then take the list of resulting questions and sort them by their difficulty, and finally begin to answer them starting with the easiest ones. For this session, that process has already been done for you, and the questions are already sorted by difficulty. In some cases, the answer to a question can be obtained from a graphic, so use them to your advantage.\n",
    "\n",
    "Those questions are grouped into 10 blocks. All questions in a block can be solved using the same strategy; e.g., to answer \"What was the maximum number of packages transported in a train?\" or \"What was the minimum number of packages transported in a train?\", we will make the same process, but changing the function that we apply to the data. Your task is to answer at least one question in each block. At the end of the workshop session, you will fill out a Moodle questionnaire with 10 questions, one for each block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 0\n",
    "\n",
    "- How many records are in the dataset?\n",
    "- How many columns are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 1\n",
    "\n",
    "- How many trains are in the dataset?\n",
    "- How many stations are in the dataset?\n",
    "- How many trips are in the dataset?\n",
    "- How many different cargo types are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 2\n",
    "\n",
    "- How many packages did train UDAXI transport?\n",
    "- How many packages of Chemicals were transported?\n",
    "- What is the maximum cargo carried by train UDAXI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 3\n",
    "- Which cargo type was transported the most?\n",
    "- Which train made more trips?\n",
    "- Which train transported the most packages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 4\n",
    "- How many trips were made in January?\n",
    "- How many packages were transported on Mondays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 5\n",
    "- Which train has the best fuel efficiency (lowest average consumption)?\n",
    "- Which train has the worst fuel efficiency (maximum average consumption)?\n",
    "- What is the average fuel consumption in the whole trip for Textiles?\n",
    "- How long lasted the shortest trip?\n",
    "- How long lasted the longest trip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 6\n",
    "- How many packages did train UDAXI transport in July?\n",
    "- How many packages were loaded on Mondays at station A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
